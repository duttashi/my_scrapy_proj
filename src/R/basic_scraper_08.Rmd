---
title: "R Notebook"
output: pdf_notebook
---

extract data from https://www.datacamp.com/community/tutorials/r-web-scraping-rvest

```{r}
library(rvest)
library(stringr)
library(rebus)
library(tidyverse)
```

```{r}
pageURL<- "https://www.trustpilot.com/review/www.amazon.com"
html<- read_html(pageURL)
```

```{r}
get_last_page<- function(pageURL){
  
  pages_data<- pageURL %>%
    html_nodes(".pagination-page") %>%
    html_text()
  
  pages_data[(length(pages_data)-1)]%>%
    # take the raw string
    unname() %>%
    # convert to number
    as.numeric()
}
```

Test the function
```{r}
first_page <- read_html(pageURL)
latest_page_number <- get_last_page(first_page)
latest_page_number
```
#### generate a list of relevant URLs
```{r}
list_of_pages <- str_c(pageURL, '?page=', 1:latest_page_number)
head(list_of_pages, 5)
```

Extract the information of One page. I want to extract the review text, rating, name of the author and time of submission of all the reviews on a subpage.

```{r}
get_reviews<- function(html){
  html %>%
    # the relevant tag
    html_nodes(".review-info__body__text")%>%
    html_text()%>%
    # Trim additional white space
    str_trim() %>%                       
    # Convert the list into a vector
    unlist()
}

# test the function
reviews<- get_reviews(html)
head(reviews, 4)
```




